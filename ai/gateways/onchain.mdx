---
title: On-chain Setup
---

The previous section covered the **off-chain** configuration of the AI Gateway
node. This section will explain how to connect an AI Gateway node to the AI
subnet and request AI inference jobs on-chain.

## Prerequisites

- A dedicated static IP address or domain name for your AI Gateway node
- A funded Ethereum account with enough ETH to cover gas fees and pay for AI
  inference jobs

## Launch your On-chain AI Gateway

After setting up your AI Gateway **off-chain**, it's time to connect it to the
AI Subnet for on-chain AI inference jobs. This process is similar to the Mainnet
Transcoding Network Gateway setup, with a few extra flags due to AI Subnet
software limitations. See the
[Mainnet Transcoding Network Gateway](/gateways/guides/gateway-overview) guide
for details. Below is a summary:

<Steps>
  <Step title="Verify Off-chain AI Gateway">
    Verify that your AI Gateway node is functioning correctly **off-chain** before connecting it to the AI Subnet. Refer to [the previous section](/ai/gateways/start-gateway) for more details.
  </Step>
  <Step title="Prepare your Ethereum account">
    Ensure your Ethereum account has enough ETH to cover gas fees and AI inference jobs. Refer to the [Fund Gateway Guide](/gateways/guides/fund-gateway) for more details.
  </Step>
  <Step title="Fund your AI Gateway">
    Fund your AI Gateway to ensure it has sufficient **deposit** and **reserve** to pay for AI inference requests. Refer to the [Deposit Gateway Funds via Livepeer CLI](/gateways/guides/fund-gateway#deposit-gateway-funds-via-livepeer-cli) guide for more information.
  </Step>
  <Step title="Configure Transcoding Options">
    Configure transcoding options, even though the AI Gateway is not a transcoding node, due to current AI Subnet software limitations. Refer to the [Transcoding Options](/gateways/guides/transcoding-options) guide for more details.
  </Step>
  <Step title="Launch an AI Gateway">
    Launch your AI Gateway node. This process is similar to the **docker** or **binary** steps in the [previous section](/ai/gateways/start-gateway), but requires additional flags to enable on-chain functionality. Here's an example:

    - `-network=arbitrum-one-mainnet`: This flag connects the AI Gateway node to the Arbitrum Mainnet network.
    - `-ethUrl=https://arb1.arbitrum.io/rpc`: This flag sets the Arbitrum Mainnet RPC URL. Replace this with your own RPC URL if needed.
    - `-ethKeystorePath=/root/.lpData/arbitrum-one-mainnet/keystore`: This flag sets the path to the AI Gateway's Ethereum keystore file.
    - `-ethAcctAddr <AI_SUBNET_ORCH_ETH_ADDRESS>`: This flag sets the Ethereum address of the AI Gateway.
    - `-ethPassword=/root/.lpData/.eth_secret`: This flag sets the path to the Ethereum keystore password file.
    - `-ethOrchAddr=<MAIN_ORCH_ETH_ADDRESS>`: This flag sets the Ethereum address of the Mainnet Transcoding Network Gateway.
    - `-maxTotalEV=100000000000000`: This flag ensures that the AI Gateway doesn't trigger maximum total ticket value limits set by the `go-livepeer` software.
    - `-maxPricePerUnit=<MAX PRICE in WEI or USD>`: This defaults to 0. Set to acceptable max price in wei (or USD, e.g. 0.02USD) willing to pay. Note: this can impact amount of Orchestrators available to process the work.
    - `-ignoreMaxPriceIfNeeded=<true or false>`: This defaults to false. Set to true if want to process requests if no Orchestrators are under maxPricePerUnit or do not want to use a max price.
    - `-maxPricePerCapability=/path/to/maxPrices.json`: This flag sets the max price per unit for one or many pipeline/models. Refer to the [Set Max Price Per Pipeline and Model](#set-max-price-per-pipeline-and-model-optional) section for more details.

  </Step>
</Steps>

## Set Max Price Per Pipeline and Model (Optional)

To avoid overpaying for AI inference jobs, you can set a maximum price per unit
for each pipeline and model. This feature is optional and can be configured
using the `-maxPricePerCapability` flag. If a price is not set for a specific
pipeline/model, the `-maxPricePerUnit` price will be used. The flag input should
be a JSON file with the specified max prices. The example below demonstrates the
following configurations:

- Set the price for the `image-to-image` pipeline and model
  `ByteDance/SDXL-Lightning` to 1,700,000 wei per unit (pixels).
- Set the price for the `text-to-image` pipeline and model
  `stabilityai/stable-diffusion-3-medium-diffusers` to 4,768,371 wei per unit
  (pixels).
- Set the price for the `upscale` pipeline for all models to 4,768,371 wei per
  unit. The `pixels_per_unit` defaults to `1` if not specified.
- Set the price for the `image-to-video` pipeline for all models to 3,390,842
  wei per unit (pixels).
- Set the price for the `audio-to-text` pipeline for all models to 12,882,811
  wei per unit (milliseconds of audio).

```json
{
  "capabilities-prices": [
    {
      "pipeline": "image-to-image",
      "model_id": "ByteDance/SDXL-Lightning",
      "price_per_unit": 1700000,
      "pixels_per_unit": 1
    },
    {
      "pipeline": "text-to-image",
      "model_id": "stabilityai/stable-diffusion-3-medium-diffusers",
      "price_per_unit": 4768371,
      "pixels_per_unit": 1
    },
    {
      "pipeline": "upscale",
      "model_id": "default",
      "price_per_unit": 4768371
    },
    {
      "pipeline": "image-to-video",
      "price_per_unit": 3390842,
      "pixels_per_unit": 1
    },
    {
      "pipeline": "audio-to-text",
      "price_per_unit": 12882811,
    }
  ]
}
```
